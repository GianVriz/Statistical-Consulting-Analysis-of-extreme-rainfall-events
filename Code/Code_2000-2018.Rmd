---
title: "Satellite data"
author: "Vriz Gian Luca"
date: "2023-04-26"
output: html_document
---

# Satellite data

## Wet days

Firtly, we load all libraries,

```{r setup, include=FALSE}
library(readr) 
library(xgboost)
library(dplyr)
library(data.table)
library(mgcv)
library(ggplot2)
library(R.matlab)
library(ggspatial)
library(EnvStats)
library(Metrics)
library(tseries)
library(raster)
library(sp)
library(keras)
library(plyr)
```

Then, we import the dataset, which is a three dimensional object with latitude, longitude and time series of wet days (value higher than 1mm).

```{r}
data_wet <- readMat('Satellite data/Wet/Satellite_wet_2000_2018.mat')
```

Here, we obtain the number of wet days for each location.

```{r}
#Coputed in Python: faster
Count <- as.numeric(data_wet[["Obj"]][[3]])
```

Obtain the number rain day for each location.

```{r}
#take time
#Count <- c()
#for (i in 1: length(data_wet[['Obj']][[3]])){
  
#if(sum(array(unlist(data_wet[['Obj']][[3]][[i]]))) == 0){Count<-append(Count, 0)}

#else{
#a <- array(unlist(data_wet[['Obj']][[3]][[i]]))
#Count <- append(Count, length(a))
#   }}
#Count
```

Satellite data.

```{r}
#x=*years*
#Count_2 <- Count/x
satellite <- as.data.frame(Count, colnames('Count'))
satellite$Latitude <- array(unlist(data_wet[["Obj"]][[1]]))
satellite$Longitude <- array(unlist(data_wet[["Obj"]][[2]]))
View(satellite)
```

Plot average number of wet days.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
world <- map_data("world", maptype = 'terrain-background',)
world <- world[world$lat <= 60 & world$lat > -60 & world$long <= 180 & world$lat > -180,]

map_1 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = satellite,
    aes(Longitude, Latitude, color= Count), size = 1, alpha = 0.008
  ) +
 labs(title = 'Satellite', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn( colours = rainbow(3), name = "Wet days")
map_1
```

## Weibull distribution using MLE

As suggested in Marra, F. et al. (2019), we  a dynamic threshold, that is ordinary events with a value higher than the 75th quantile.

```{r}
data_2 <- readMat('Satellite data/ Quantile/Satellite_all_2000_2018_75.mat')
```

We first estimates the parameters of the Weibull model considering MLE.

```{r, warning = FALSE}
Scale <- c()
Shape <- c()
for (i in 1: length(data_2[['Obj']][[3]])){
a <- array(unlist(data_2[['Obj']][[3]][[i]]))

if(length(unique(a)) <= 1){Scale <- append(Scale, 0)
   Shape<-append(Shape,0)}

else{
est <- eweibull(as.numeric(a), method = "mle")
Scale <- append(Scale, est$parameters[2])
Shape <- append(Shape, est$parameters[1])
   }}
Scale
```

Satellite data.

```{r}
satellite <- as.data.frame(Shape, colnames('Shape'))
satellite$Scale <- Scale
satellite$Latitude <- array(unlist(data_wet[["Obj"]][[1]]))
satellite$Longitude <- array(unlist(data_wet[["Obj"]][[2]]))
```

Histogram wet days.

```{r}
hist(Shape, breaks = 100000, col='red', xlab='Scale parameter', main = 'Histogram', xlim=c(0,4))
```

Plot scale parameter.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_2 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = satellite,
    aes(Longitude, Latitude, color= Scale), size = 1, alpha = 0.008
  ) +
 labs(title = 'Satellite', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(0,60), colours = rainbow(3), name = "Scale Parameter")
map_2
```

Plot shape parameter.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_3 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = satellite,
    aes(Longitude, Latitude, color= Shape), size = 1, alpha = 0.008
  ) +
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits=c(0,4),colours = rainbow(3), name = "Shape parameter")
map_3
```

Histogram shape parameter.

```{r}
hist(Shape, breaks = 10000, col='red', xlab='Scale parameter', main = 'Histogram', xlim=c(0,10))
```

# Station data

In the following, we will perform the same procedure considering station data.

## Wet days

Firstly, we have to obtain the number of wet days for each station.

```{r}
data_station <- readMat('Station data/Rain_data_2000_2018_75_alt.mat')
```

Station data.

```{r}
Count_2 <- t(data_station[["Obj"]][[5]])
station <- as.data.frame(Count_2)
station$Latitude <- as.numeric(data_station[["Obj"]][[1]])
station$Longitude <- as.numeric(unlist(data_station[["Obj"]][[2]]))
colnames(station)[1] ="Count"
station <- station[station$Latitude <= 60 & station$Latitude > -60 & station$Longitude <= 180 & station$Longitude > -180,]
View(station)
```

Plot wet days.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_4 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = station,
    aes(Longitude, Latitude, color= Count), size = 1
  )+
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(0,365),colours = rainbow(3), name = "Wet days")
map_4
```

## Weibull distribution using MLE

Then, we will estimate the parameters of the Weibull distribution using MLE.

```{r,warning=FALSE}
#take time
Scale_2 <- c()
Shape_2 <- c()
for (i in 1:length(data_station[['Obj']][[4]])){

a <- array(unlist(data_station[['Obj']][[4]][[i]]))
if(length(unique(a)) <= 1){Scale_2 <- append(Scale_2, 0)
   Shape_2 <- append(Shape_2, 0)}

else{
a <- array(unlist((data_station[['Obj']][[4]][[i]])))
est_2 <- eweibull(as.numeric(a), method = "mle")
Scale_2 <- append(Scale_2, est_2$parameters[2])
Shape_2 <- append(Shape_2, est_2$parameters[1])
   }}
```

Station data.

```{r}
station <- as.data.frame(Shape_2, colnames('Shape'))
station$Scale <- Scale_2
station$Latitude <- as.numeric(data_station[["Obj"]][[1]])
station$Longitude <- as.numeric(data_station[["Obj"]][[2]])
station <- station[station$Latitude <= 60 & station$Latitude > -60 & station$Longitude <= 180 & station$Longitude > -180,]
colnames(station)[1] ="Shape"
View(station)
```

Plot scale parameter.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_5 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = station,
    aes(Longitude, Latitude, color= Scale), size = 1
  ) +
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(0,60),colours = rainbow(3), name = "Scale parameter")
map_5
```

Plot shape parameter.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_6 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = station,
    aes(Longitude, Latitude, color= Shape), size = 1
  ) +
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(0,4),colours = rainbow(3), name = "Shape parameter")
map_6
```
# Weibull distribution using LS

In the following we estimate the parameters using also the least squares regression in Weibull-transformed coordinates approach (Marra, F. et al., 2019).

## Satellite data

Least squares regression in Weibull-transformed coordinates for satellite data.

```{r warning = FALSE}
#Estimation of tyhe Weibull parameter: take time
Scale_3 <- c()
Shape_3 <- c()
for (i in 1:length(data_2[['Obj']][[3]])){
a <- array(unlist(data_2[['Obj']][[3]][[i]]))

if(length(unique(a)) <= 1){Scale_3 <- append(Scale_3, 0)
   Shape_3<-append(Shape_3,0)}

else{
Y <- log(sort(a))
F <- (c(1:length(a))/(length(a)+1))
X <- log(-log(1-F))
reg <- lm(Y~X) 

shape <- 1/reg[["coefficients"]][["X"]]
scale <- exp(reg[["coefficients"]][["(Intercept)"]])

Shape_3 <- append(Shape_3, shape)
Scale_3 <- append(Scale_3, scale)
   }}
Scale_3
```

Satellite data.

```{r}
satellite <- as.data.frame(Shape_3, colnames('Shape'))
satellite$Scale <- Scale_3
satellite$Latitude <- array(unlist(data_wet[["Obj"]][[1]]))
satellite$Longitude <- array(unlist(data_wet[["Obj"]][[2]]))
colnames(satellite)[1] = "Shape"
```

Plot scale parameter. 

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_7 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = satellite,
    aes(Longitude, Latitude, color= Scale), size = 1, alpha = 0.008
  ) +
 labs(title = 'Satellite', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(0,60), colours = rainbow(3), name = "Scale Parameter")
map_7
```

Histogram shape parameter.

```{r}
quantile(Scale_3, 0.99) #quantile 99
hist(Scale_3, breaks=100, col="red", xlab="Scale parameter", xlim=c(0,100),
   main="Histogram")
```

Plot shape parameter.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_8 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = satellite,
    aes(Longitude, Latitude, color= Shape), size = 1, alpha = 0.008
  ) +
 labs(title = 'Satellite', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits=c(0,4),colours = rainbow(3), name = "Shape parameter")
map_8
```

Histogram shape parameter

```{r}
quantile(Shape_3, 0.99) #99 quantile
hist(Shape_3, breaks=10000, col="red", xlab="Scale parameter", xlim=c(0,10),
   main="Histogram")
```

## Station data

Least squares regression in Weibull-transformed coordinates for station data.

```{r,warning=FALSE}
Scale_4 <- c()
Shape_4 <- c()
for (i in 1:length(data_station[['Obj']][[4]])){
a <- array(unlist(data_station[['Obj']][[4]][[i]]))

if(length(unique(a)) <= 1){Scale_4 <- append(Scale_4, 0)
   Shape_4<-append(Shape_4,0)}

else{
Y <- log(sort(a))
F <- (c(1:length(a))/(length(a)+1))
X <- log(-log(1-F))
reg <- lm(Y~X) 

shape <- 1/reg[["coefficients"]][["X"]]
scale <- exp(reg[["coefficients"]][["(Intercept)"]])

Shape_4 <- append(Shape_4, shape)
Scale_4 <- append(Scale_4, scale)
   }}
Scale_4
```

Station data.

```{r}
station <- as.data.frame(Shape_4, colnames('Shape'))
station$Scale <- Scale_4
station$Latitude <- as.numeric(data_station[["Obj"]][[1]])
station$Longitude <- as.numeric(data_station[["Obj"]][[2]])
colnames(station)[1] ="Shape"
station <- station[station$Latitude <= 60 & station$Latitude > -60 & station$Longitude <= 180 & station$Longitude > -180,]
View(station)
```

Plot scale parameter 

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_9 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = station,
    aes(Longitude, Latitude, color= Scale), size = 1
  ) +
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(0,60),colours = rainbow(3), name = "Scale parameter")
map_9
```

Plot shape parameter.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_10 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = station,
    aes(Longitude, Latitude, color= Shape), size = 1
  ) +
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(0,4),colours = rainbow(3), name = "Shape parameter")
map_10
```

## Matching values for error correction

In the following we will merge data station and satellite data by coordinates. The coordinates in the dataset are in different format, then we have to approximate to merge all values.

```{r}
satellite <- as.data.frame(Shape_3, colnames('Shape'))
satellite$Scale <- Scale_3
satellite$Latitude <- array(unlist(data_2[["Obj"]][[1]]))
satellite$Longitude <- array(unlist(data_2[["Obj"]][[2]]))
colnames(satellite)[1] = "Shape"
satellite$Count<-Count

station <- as.data.frame(Shape_4, colnames('Shape'))
station$Scale <- Scale_4
station$Latitude <- as.numeric(data_station[["Obj"]][[1]])
station$Longitude <- as.numeric(data_station[["Obj"]][[2]])
colnames(station)[1] = "Shape"
station$Count<-Count_2
station$Altitude<-as.numeric(data_station[["Obj"]][[3]])
station <- station[station$Latitude < 60 & station$Latitude > -60 & station$Longitude < 180 & station$Longitude > -180,]

satellite$Cord <-apply(satellite[,c("Latitude","Longitude")], 1, FUN=function(x) {paste(x[1],x[2],sep=", ") })

station$Cord <-apply(station[,c("Latitude","Longitude")], 1, FUN=function(x) {paste(round_any(x[1],0.250)-0.125,round_any(x[2],0.250)-0.125,sep=", ") })

sat_stat <- subset(satellite, Cord %in% as.vector(station$Cord))
sat_stat <- sat_stat %>% dplyr::select(1,2,5,6)
```

Now, we obtain errors as well as the MSE between satellite data and station data.

```{r}
all<-merge(sat_stat, station, by=c("Cord","Cord"))
all$err_shape <- all$Shape.y-all$Shape.x
all$err_scale <- all$Scale.y-all$Scale.x
all$err_wet <- all$Count.y-all$Count.x

mean(all$err_wet^2)
mean(all$err_scale^2)
mean(all$err_shape^2)
```

```{r}
shapiro.test(all$err_wet)
hist(all$err_wet, xlab='Station', ylab='Error', main='Histogram')
plot(density(all$err_wet),xlab='Station', ylab='Error', main='Density')
abline(v=quantile(all$err_wet, c(0.05,0.95)), lty=2, col ='red')

plot(all$err_wet, type='l', xlab='Station', ylab='Error wet days', main='Series')
abline(h=mean(all$err_wet), col='red', type='dashed')

adf.test(all$err_wet)
```


```{r}
shapiro.test(all$err_scale)
hist(all$err_scale, xlab='Station', ylab='Error', main='Histogram')
plot(density(all$err_scale),xlab='Station', ylab='Error', main='Density')
abline(v=quantile(all$err_scale, c(0.05,0.95)), lty=2, col ='red')

plot(all$err_scale, type='l', xlab='Station', ylab='Error Scale parameter', main='Series')
abline(h=mean(all$err_scale), col='red', type='dashed')

adf.test(all$err_scale)
```

```{r}
shapiro.test(all$err_shape)
hist(all$err_shape, xlab='Station', ylab='Error', main='Histogrma')
plot(density(all$err_shape), xlab='Station', ylab='Error', main='Density')
abline(v=quantile(all$err_shape, c(0.05,0.95)), lty=2, col ='red')

plot(all$err_shape, type='l', xlab='Station', ylab='Error shape parameter', main='Series')
abline(h=mean(all$err_shape), col='red')

adf.test(all$err_shape)
```

Plot error scale parameter.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_11 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = all,
    aes(Longitude, Latitude, color= err_scale), size = 1
  ) +
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(-25,25),colours = rainbow(3), name = "Error scale parameter")
map_11
```

Plot error shape parameter.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_12 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = all,
    aes(Longitude, Latitude, color= err_shape), size = 1
  ) +
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(-1,1),colours = rainbow(3), name = "Error shape parameter")
map_12
```

Plot error wet days.

```{r}
theme_update(plot.title = element_text(hjust = 0.5))
map_13 <- ggplot() +
  geom_map(
    data = world, map = world,
    aes(long, lat, map_id = region),
    color = "black", fill = "lightgray", size = 0.3
  ) +
  geom_point(
    data = all,
    aes(Longitude, Latitude, color= err_wet), size = 1
  ) +
 labs(title = 'World stations', x = "Longitude", y = "Latitude") +
    annotation_north_arrow(location = "bl", which_north = "true", 
        pad_x = unit(0.2, "in"), pad_y = unit(0.2, "in"),
        style = north_arrow_fancy_orienteering)+
  scale_color_gradientn(limits = c(-120,120),colours = rainbow(3), name = "Error wet days")
map_13
```

## New variables 

Before performing extrapolation we decide to add other variables. These are variables related to climate conditions available from WorldClim platform (https://worldclim.org/).

```{r}
r <- getData("worldclim",var="bio",res=10) # if problems restart R
r <- r[[c(1,3,7,12)]]
points <- all %>% dplyr::select(8,7)

values <- extract(r,points)
all_2 <- cbind.data.frame(all,values)
all_2$Count.y<-as.numeric(all_2$Count.y)
all_2$err_wet<-as.numeric(all_2$err_wet)
```

## Model wet days

The first variable under analysis is the number of wet days in 2018. We performs different types of models: linear regression, GAM, Artificial Neural Networks (ANN) and XGBoost.

```{r}
all_3 <- all_2 %>% dplyr::select(4,7,8,9,10,14,15,16,17)
all_3[is.na(all_3)] <- 0
#make this example reproducible
set.seed(1)

#use 80% of dataset as training set and 20% as test set
sample <- sample(c(TRUE, FALSE), nrow(all_3), replace=TRUE, prob=c(0.8,0.2))
train <- all_3[sample, ]
test <- all_3[!sample, ]
cat("RMSE:", rmse(test$Count.y, test$Count.x))
```

Linear regression.
```{r}
reg_l<-lm(Count.y~Count.x+Longitude+Latitude+bio1+bio3+bio7+bio12+Altitude, data=train)
summary(reg_l)

pred_reg <- predict(reg_l,test)

cat("RMSE:", rmse(test$Count.y, pred_reg))
```
GAM.

```{r}
GAM <- gam(Count.y ~ s(Count.x,bs='cc')+ s(bio1,bs="bs")+ s(Longitude,bs="bs")+s(Latitude,bs="bs")+s(bio3, bs='bs')+s(bio7, bs='bs')+s(bio12,bs='bs'), data = train ,method="REML")
summary(GAM)

pred <- predict.gam(GAM,test)

cat("RMSE:", rmse(test$Count.y, pred))
```

XGBoost.

```{r}
xtrain = data.matrix(train[,-4])
ytrain = train[,4]
xtest = data.matrix(test[,-4])
ytest = test[,4]

xgb_train = xgb.DMatrix(data = xtrain, label = ytrain)
xgb_test = xgb.DMatrix(data = xtest, label = ytest)

watchlist = list(train=xgb_train, test=xgb_test)

#create hyperparameter grid
max.depths = c(2, 3, 5, 6, 7)
etas = c(0.01, 0.02, 0.35)

best_params = 0
best_score = 0

count = 1
for( depth in max.depths ){
    for( num in etas){

        bst_grid = xgb.train(data = xgb_train, 
                                max.depth = depth, 
                                eta=num, 
                                nthread = 2, 
                                nround = 1000, 
                                watchlist = watchlist, 
                                objective = "reg:squarederror", 
                                early_stopping_rounds = 50, 
                                verbose=0)

        if(count == 1){
            best_params = bst_grid$params
            best_score = bst_grid$best_score
            count = count + 1
            }
        else if( bst_grid$best_score < best_score){
            best_params = bst_grid$params
            best_score = bst_grid$best_score
        }
    }
}

best_params
best_score
```

```{r}
#fit XGBoost model and display training and testing data at each iteartion
#xgb.train(data = xgb_train, max.depth = 2, watchlist=watchlist, nrounds = 1000)

model_xgb = xgb.train(data = xgb_train, nthread = 2, eta = 0.02, max.depth = 6, nrounds = 1000, watchlist = watchlist, objective = "reg:squarederror", early_stopping_rounds = 50,  verbose = 1)

summary(model_xgb)

pred_xgb = predict(model_xgb, xgb_test)

cat("RMSE:", rmse(ytest, pred_xgb))

x = 1:length(ytest)                   # visualize the model, actual and predicted data
plot(x, ytest, col = "blue", type = "l", xlab='Stations',ylab = 'Average number of wet days')
lines(x, pred_xgb, col = "red", type = "l")
legend("topleft", legend = c("y-test", "y-pred"),
       col = c("blue", "red"), lty=1, cex=0.7, lwd=2, bty='n')
```

```{r}
importance <- xgb.importance(feature_names = colnames(xgb_test),model = model_xgb)
print(xgb.ggplot.importance(importance_matrix = importance))
```

ANN.
```{r}

set.seed(1)

maxs <- apply(all_3, 2, max) 
mins <- apply(all_3, 2, min)
scaled <- as.data.frame(scale(all_3, center = mins, 
                              scale = maxs - mins))

train <- scaled[sample, ]
test <- scaled[!sample, ]

xtrain = as.matrix(train[,-4])
ytrain = as.matrix(train[,4])
xtest = as.matrix(test[,-4])
ytest = as.matrix(test[, 4])

xtrain = array(xtrain, dim = c(nrow(xtrain), dim(xtrain)[2], 1))
xtest = array(xtest, dim = c(nrow(xtest), dim(xtest)[2], 1))
dim(xtrain)
dim(xtest)

in_dim = c(dim(xtrain)[2:3])
print(in_dim)

model = keras_model_sequential() %>%
  layer_conv_1d(filters = 64, kernel_size = 2,
               input_shape = in_dim, activation = "relu") %>%
  layer_flatten() %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = 1, activation = "linear")
 
model %>% compile(
  loss = "mse",
  optimizer = "adam")

model %>% summary()
```

```{r}
model %>% fit(xtrain, ytrain, epochs = 100, batch_size=16, verbose = 0)
scores = model %>% evaluate(xtrain, ytrain, verbose = 0)
print(scores)
```

```{r}
ypred = model %>% predict(xtest)

ypred <- ypred * (max(all_3$Count.y) - min(all_3$Count.y)) + min(all_3$Count.y)
ytest <- (ytest) * (max(all_3$Count.y) - min(all_3$Count.y)) +min(all_3$Count.y)

cat("RMSE:", rmse(ytest, ypred))
```

```{r}
x_axes = seq(1:length(ypred))
plot(x_axes, ytest, ylim = c(min(ypred), max(ytest)),
     col = "blue", type = "l", lwd = 2, ylab = "Wet days", xlab = 'Stations')
lines(x_axes, ypred, col = "red", type = "l", lwd = 2)
legend("topleft", legend = c("y-test", "y-pred"),
       col = c("blue", "red"), lty=1, cex=0.7, lwd=2, bty='n')
```


The XGBoost turned out to be the best model in terms of RMSE

## Model scale

The same procedure is performed considering the scale parameter.

```{r}
#xall = data.matrix(all_3[,-4])
#yall = all_3[,4]

#xgb_all = xgb.DMatrix(data = xall, label = yall)
#Count.pred = predict(model_xgb, xgb_all)
```

```{r}
all_3 <- all_2 %>% dplyr::select(3,6,7,8,4,10,14,15,16,17)
#all_3$Count.x<-Count.pred
all_3[is.na(all_3)] <- 0
#make this example reproducible
set.seed(1)

#use 80% of dataset as training set and 20% as test set
sample <- sample(c(TRUE, FALSE), nrow(all_3), replace=TRUE, prob=c(0.8,0.2))
train <- all_3[sample, ]
test <- all_3[!sample, ]
cat("RMSE:", rmse(test$Scale.y, test$Scale.x))
```

Linear regresison.

```{r}
reg_l<-lm(Scale.y~Scale.x+Longitude+bio1, data=train)
summary(reg_l)

pred_reg <- predict(reg_l,test)

cat("RMSE:", rmse(test$Scale.y, pred_reg))
```
GAM.

```{r}
GAM <- gam(Scale.y ~ s(Scale.x, bs="cc")+s(Longitude,bs="bs")+s(Latitude,bs="bs")+s(Altitude, bs='bs'), data = train ,method="REML")
summary(GAM)

pred <- predict.gam(GAM,test)

cat("RMSE:", rmse(test$Scale.y, pred))

```

XGBoost.


```{r}
#tunning parameters
xtrain = data.matrix(train[,-2])
ytrain = train[,2]
xtest = data.matrix(test[,-2])
ytest = test[,2]

xgb_train = xgb.DMatrix(data = xtrain, label = ytrain)
xgb_test = xgb.DMatrix(data = xtest, label = ytest)

watchlist = list(train=xgb_train, test=xgb_test)

#create hyperparameter grid
max.depths = c(2, 3, 4, 5, 6, 7, 10)
etas = c(0.01, 0.02, 0.1, 0.2, 0.3, 0.32, 0.35, 0.37, 0.38, 0.4, 0.5)

best_params = 0
best_score = 0

count = 1
for( depth in max.depths ){
    for( num in etas){

        bst_grid = xgb.train(data = xgb_train, 
                                max.depth = depth, 
                                eta=num, 
                                nthread = 2, 
                                nround = 1000, 
                                watchlist = watchlist, 
                                objective = "reg:squarederror", 
                                early_stopping_rounds = 50, 
                                verbose=0)

        if(count == 1){
            best_params = bst_grid$params
            best_score = bst_grid$best_score
            count = count + 1
            }
        else if( bst_grid$best_score < best_score){
            best_params = bst_grid$params
            best_score = bst_grid$best_score
        }
    }
}

best_params
best_score
```

```{r}
#fit XGBoost model and display training and testing data at each iteartion
#xgb.train(data = xgb_train, max.depth = 2, watchlist=watchlist, nrounds = 1000)

model_xgb = xgb.train(data = xgb_train,nthread = 2, eta = 0.35, max.depth = 3, nrounds = 1000, watchlist = watchlist, objective = "reg:squarederror", early_stopping_rounds = 50,  verbose = 1)

summary(model_xgb)

pred_xgb = predict(model_xgb, xgb_test)

cat("RMSE:", rmse(ytest, pred_xgb))

x = 1:length(ytest)                   # visualize the model, actual and predicted data
plot(x, ytest, col = "blue", type = "l", xlab='Stations',ylab = 'Scale parameter')
lines(x, pred_xgb, col = "red", type = "l")
legend("topleft", legend = c("y-test", "y-pred"),
       col = c("blue", "red"), lty=1, cex=0.7, lwd=2, bty='n')
```

```{r}
importance <- xgb.importance(feature_names = colnames(xgb_test),model = model_xgb)
print(xgb.ggplot.importance(importance_matrix = importance))
```

ANN.

```{r}
set.seed(1)

maxs <- apply(all_3, 2, max) 
mins <- apply(all_3, 2, min)
scaled <- as.data.frame(scale(all_3, center = mins, 
                              scale = maxs - mins))

train <- scaled[sample, ]
test <- scaled[!sample, ]

xtrain = as.matrix(train[,-2])
ytrain = as.matrix(train[,2])
xtest = as.matrix(test[,-2])
ytest = as.matrix(test[, 2])

xtrain = array(xtrain, dim = c(nrow(xtrain), dim(xtrain)[2], 1))
xtest = array(xtest, dim = c(nrow(xtest), dim(xtest)[2], 1))
dim(xtrain)
dim(xtest)

in_dim = c(dim(xtrain)[2:3])
print(in_dim)

model = keras_model_sequential() %>%
  layer_conv_1d(filters = 64, kernel_size = 2,
               input_shape = in_dim, activation = "relu") %>%
  layer_flatten() %>%
  layer_dense(units = 32, activation = "relu") %>%
  layer_dense(units = 1, activation = "linear")
 
model %>% compile(
  loss = "mse",
  optimizer = "adam")

model %>% summary()
```

```{r}
model %>% fit(xtrain, ytrain, epochs = 100, batch_size=16, verbose = 0)
scores = model %>% evaluate(xtrain, ytrain, verbose = 0)
print(scores)
```

```{r}
ypred = model %>% predict(xtest)

ypred = model %>% predict(xtest)

ypred <- ypred* (max(all_3$Scale.y) - min(all_3$Scale.y)) + min(all_3$Scale.y)
ytest <- (ytest) * (max(all_3$Scale.y) - min(all_3$Scale.y)) +min(all_3$Scale.y)

cat("RMSE:", rmse(ytest, ypred))
```

```{r}
x_axes = seq(1:length(ypred))
plot(x_axes, ytest, ylim = c(min(ypred), max(ytest)),
     col = "blue", type = "l", lwd = 2, ylab = "Wet days", xlab = 'Stations')
lines(x_axes, ypred, col = "red", type = "l", lwd = 2)
legend("topleft", legend = c("y-test", "y-pred"),
       col = c("blue", "red"), lty=1, cex=0.7, lwd=2, bty='n')
```

## Model shape

The same procedure is performed considering the shape parameter.

```{r}
all_3 <- all_2 %>% dplyr::select(2,4,5,7,8,10,14,15,16,17)
#all_3$Count.x<-Count.pred
all_3[is.na(all_3)] <- 0
#make this example reproducible
set.seed(3)

#use 80% of dataset as training set and 20% as test set
sample <- sample(c(TRUE, FALSE), nrow(all_3), replace=TRUE, prob=c(0.8,0.2))
train <- all_3[sample, ]
test <- all_3[!sample, ]
cat("RMSE:", rmse(test$Shape.y, test$Shape.x))
```

Linear regression.

```{r}
#Linear regression
reg_l<-lm(Shape.y~Longitude+Latitude+bio12+Shape.x, data=train)
summary(reg_l)

pred_reg <- predict(reg_l,test)

cat("RMSE:", rmse(test$Shape.y, pred_reg))
```
GAM.

```{r}
GAM <- gam(Shape.y ~ Longitude+Latitude+s(bio12,bs='bs'), data = train ,method="REML")
summary(GAM)

pred <- predict.gam(GAM,test)

cat("RMSE:", rmse(test$Shape.y, pred))
```

XGBoost.

```{r}
#tunning parameters
xtrain = data.matrix(train[,-3])
ytrain = train[,3]
xtest = data.matrix(test[,-3])
ytest = test[,3]

xgb_train = xgb.DMatrix(data = xtrain, label = ytrain)
xgb_test = xgb.DMatrix(data = xtest, label = ytest)

watchlist = list(train=xgb_train, test=xgb_test)

#create hyperparameter grid
max.depths = c(2, 3, 4, 5, 6, 7, 10)
etas = c(0.005, 0.1, 0.2, 0.35, 0.4, 0.5, 0.55, 0.6, 0.65, 0.7, 0.8)

best_params = 0
best_score = 0

count = 1
for( depth in max.depths ){
    for( num in etas){

        bst_grid = xgb.train(data = xgb_train, 
                                max.depth = depth, 
                                eta=num, 
                                nthread = 2, 
                                nround = 1000, 
                                watchlist = watchlist, 
                                objective = "reg:squarederror", 
                                early_stopping_rounds = 50, 
                                verbose=0)

        if(count == 1){
            best_params = bst_grid$params
            best_score = bst_grid$best_score
            count = count + 1
            }
        else if( bst_grid$best_score < best_score){
            best_params = bst_grid$params
            best_score = bst_grid$best_score
        }
    }
}

best_params
best_score
```

```{r}
#fit XGBoost model and display training and testing data at each iteartion
#xgb.train(data = xgb_train, max.depth = 2, watchlist=watchlist, nrounds = 1000)

model_xgb = xgb.train(data = xgb_train,nthread = 2, eta = 0.6, max.depth = 2, nrounds = 1000, watchlist = watchlist, objective = "reg:squarederror", early_stopping_rounds = 50,  verbose = 1)

summary(model_xgb)

pred_xgb = predict(model_xgb, xgb_test)

cat("RMSE:", rmse(ytest, pred_xgb))

x = 1:length(ytest)                   # visualize the model, actual and predicted data
plot(x, ytest, col = "blue", type = "l", xlab='Stations',ylab = 'Scale parameter')
lines(x, pred_xgb, col = "red", type = "l")
legend("topleft", legend = c("y-test", "y-pred"),
       col = c("blue", "red"), lty=1, cex=0.7, lwd=2, bty='n')
```

```{r}
importance <- xgb.importance(feature_names = colnames(xgb_test),model = model_xgb)
print(xgb.ggplot.importance(importance_matrix = importance))
```

ANN.

```{r}
set.seed(1)

maxs <- apply(all_3, 2, max) 
mins <- apply(all_3, 2, min)
scaled <- as.data.frame(scale(all_3, center = mins, 
                              scale = maxs - mins))

train <- scaled[sample, ]
test <- scaled[!sample, ]

xtrain = as.matrix(train[,-3])
ytrain = as.matrix(train[,3])
xtest = as.matrix(test[,-3])
ytest = as.matrix(test[, 3])

xtrain = array(xtrain, dim = c(nrow(xtrain), dim(xtrain)[2], 1))
xtest = array(xtest, dim = c(nrow(xtest), dim(xtest)[2], 1))
dim(xtrain)
dim(xtest)

in_dim = c(dim(xtrain)[2:3])
print(in_dim)

model = keras_model_sequential() %>%
  layer_conv_1d(filters = 64, kernel_size = 2,
               input_shape = in_dim, activation = "relu") %>%
  #layer_conv_1d(filters = 64, kernel_size = 2,
   #           input_shape = in_dim, activation = "relu") %>%
  layer_flatten() %>%
  layer_dense(units = 32, activation = "relu") %>%
  
  layer_dense(units = 16, activation = "relu") %>%
  
  layer_dense(units = 1, activation = "linear")
 
 
model %>% compile(loss = 'mse',
                  optimizer = 'adam',
                  metrics = list("mean_absolute_error")
                   )
 
model %>% summary()

```

```{r}
model %>% fit(xtrain, ytrain, epochs = 100, batch_size=32, shuffle = FALSE, verbose = 0)
scores = model %>% evaluate(xtrain, ytrain, verbose = 0)
print(scores)
```

```{r}
ypred = model %>% predict(xtest)

ypred <- ypred* (max(all_3$Shape.y) - min(all_3$Shape.y)) + min(all_3$Shape.y)
ytest <- (ytest) * (max(all_3$Shape.y) - min(all_3$Shape.y)) +min(all_3$Shape.y)

cat("RMSE:", rmse(ytest, ypred))
```


```{r}
x_axes = seq(1:length(ypred))
plot(x_axes, ytest, ylim = c(min(ypred), max(ytest)),
     col = "blue", type = "l", lwd = 2, ylab = "Shape parameter", xlab = 'Stations')
lines(x_axes, ypred, col = "red", type = "l", lwd = 2)
legend("topleft", legend = c("y-test", "y-pred"),
       col = c("blue", "red"), lty=1, cex=0.7, lwd=2, bty='n')
```

## Error computation

## Model scale

The same procedure is performed considering the scale parameter.

```{r}
#xall = data.matrix(all_3[,-4])
#yall = all_3[,4]

#xgb_all = xgb.DMatrix(data = xall, label = yall)
#Count.pred = predict(model_xgb, xgb_all)
```

```{r}
all_3 <- all_2 %>% dplyr::select(2,5,11,7,8,4,10,14,15,16,17)
#all_3$Count.x<-Count.pred
all_3[is.na(all_3)] <- 0
#make this example reproducible
set.seed(3)

#use 80% of dataset as training set and 20% as test set
sample <- sample(c(TRUE, FALSE), nrow(all_3), replace=TRUE, prob=c(0.8,0.2))
train <- all_3[sample, ]
test <- all_3[!sample, ]
x_sat <- test[1]
y_real <- test[2]
train <- train[3:11]
test <- test[3:11]
```

XGBoost.


```{r}
#tunning parameters
xtrain = data.matrix(train[,-1])
ytrain = train[,1]
xtest = data.matrix(test[,-1])
ytest = test[,1]

xgb_train = xgb.DMatrix(data = xtrain, label = ytrain)
xgb_test = xgb.DMatrix(data = xtest, label = ytest)

watchlist = list(train=xgb_train, test=xgb_test)

#create hyperparameter grid
max.depths = c(2, 3, 4, 5, 6, 7, 10)
etas = c(0.005,0.01, 0.02, 0.1, 0.2, 0.3, 0.32, 0.35, 0.37, 0.38, 0.4, 0.5,1,4)

best_params = 0
best_score = 0

count = 1
for( depth in max.depths ){
    for( num in etas){

        bst_grid = xgb.train(data = xgb_train, 
                                max.depth = depth, 
                                eta=num, 
                                nthread = 2, 
                                nround = 1000, 
                                watchlist = watchlist, 
                                objective = "reg:squarederror", 
                                early_stopping_rounds = 50, 
                                verbose=0)

        if(count == 1){
            best_params = bst_grid$params
            best_score = bst_grid$best_score
            count = count + 1
            }
        else if( bst_grid$best_score < best_score){
            best_params = bst_grid$params
            best_score = bst_grid$best_score
        }
    }
}

best_params
best_score
```

```{r}
#fit XGBoost model and display training and testing data at each iteartion
#xgb.train(data = xgb_train, max.depth = 2, watchlist=watchlist, nrounds = 1000)

model_xgb = xgb.train(data = xgb_train,nthread = 2, eta = 0.4, max.depth = 4, nrounds = 1000, watchlist = watchlist, objective = "reg:squarederror", early_stopping_rounds = 50,  verbose = 1)

summary(model_xgb)

pred_xgb = predict(model_xgb, xgb_test)

cat("RMSE:", rmse(ytest, pred_xgb))

x = 1:length(ytest)                   # visualize the model, actual and predicted data
plot(x, ytest, col = "blue", type = "l", xlab='Stations',ylab = 'Scale parameter')
lines(x, pred_xgb, col = "red", type = "l")
legend("topleft", legend = c("y-test", "y-pred"),
       col = c("blue", "red"), lty=1, cex=0.7, lwd=2, bty='n')
```

```{r}
importance <- xgb.importance(feature_names = colnames(xgb_test),model = model_xgb)
print(xgb.ggplot.importance(importance_matrix = importance))
```

```{r}
y_real$Shape_pred <- as.numeric(x_sat$Shape.x+pred_xgb)
cat("RMSE:", rmse(y_real$Shape.y,y_real$Shape_pred))

x = 1:length(y_real$Shape.y)                   # visualize the model, actual and predicted data
plot(x, y_real$Shape.y, col = "blue", type = "l", xlab='Stations',ylab = 'Scale parameter')
lines(x, y_real$Shape_pred, col = "red", type = "l")
legend("topleft", legend = c("y-test", "y-pred"),
       col = c("blue", "red"), lty=1, cex=0.7, lwd=2, bty='n')
```



